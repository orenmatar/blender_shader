{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9915f3d9-54db-4d5d-ae68-3f9ce88fde7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib ipympl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import clipboard\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "import networkx as nx\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import neptune\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import VGG16_Weights\n",
    "sys.path.append('/Users/orenm/BlenderShaderProject/project_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a318e5ee-7718-40f1-adb3-ee80cf8e4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Logic.utils import lc\n",
    "from Logic.data_loaders import create_dataloaders, evaluate_model_by_attribute\n",
    "from Logic.NN_makers import make_siamese_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99d0e29-e80c-404e-83be-09d3a1e3db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import IPython.display as dp\n",
    "from pstats import Stats\n",
    "\n",
    "# pip install gprof2dot\n",
    "\n",
    "def profile(exec_code):\n",
    "    cProfile.run(exec_code, filename='/tmp/cprof.pstats')\n",
    "    !gprof2dot -f pstats /tmp/cprof.pstats | dot -Tpng -o /tmp/output.png\n",
    "    return dp.Image(filename='/tmp/output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb0fff1-1609-4835-9068-d8ec4e992173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9f500f-14ee-4d07-af7f-b39a5ecbc57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPTUNE_KEY = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjYTQ2MmQ1YS1mNTc0LTRkMDgtYWU1My02MTQ0MWIyNDdlNzUifQ==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbe1bde-bd06-4954-8cbc-d0ae42208734",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/orenm/BlenderShaderProject/data/'\n",
    "images_path = os.path.join(path, 'images/')\n",
    "models_path = os.path.join(path, 'models/')\n",
    "db_path = os.path.join(path, 'DB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec8c4d6-20aa-4c05-80ab-483da27f9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(path, 'texture_cls_pairs.json')\n",
    "with open(file_path, \"rb\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29546c5f-a3e0-4009-ae18-f60266096f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['similar_pairs', 'different_pairs_random', 'different_pairs_cluster', 'cat_numeric_pairs', 'important_params_pairs'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00dda667-de75-43f7-aaab-7d92532240bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(pairs, *labels):\n",
    "    return [(x[0], x[1], *labels) for x in pairs]\n",
    "\n",
    "dataset = []\n",
    "for pair_type in ['different_pairs_random', 'different_pairs_cluster', 'cat_numeric_pairs', 'important_params_pairs']:\n",
    "    dataset.extend(add_labels(data[pair_type], 0, pair_type))\n",
    "\n",
    "dataset.extend(add_labels(data['similar_pairs'], 1, 'similar_pairs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4534f644-f728-4049-a455-909a674ea17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158304"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880d9cae-4ec3-4b54-87bd-424693820603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampled_dataset = random.sample(dataset, k=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae3264b-a549-46a5-950a-56348feb7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3\n",
       "similar_pairs              0.38758\n",
       "different_pairs_cluster    0.18984\n",
       "different_pairs_random     0.18798\n",
       "important_params_pairs     0.13106\n",
       "cat_numeric_pairs          0.10354\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sampled_dataset)[3].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64bc84cc-a0aa-4054-9409-860d4b0e353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 324928\n"
     ]
    }
   ],
   "source": [
    "possible_layers_to_stop_at = [(8, 128),(10, 128),(15, 256),(17, 256), (22, 512),(24, 512)]\n",
    "layers_to_take = (10, 128)\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs=4\n",
    "\n",
    "log_interval = 100\n",
    "\n",
    "model = make_siamese_vgg(layers_to_take)\n",
    "print(\"model params:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2997f0a0-bc97-431e-895f-aa209a05551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3aedbb4-cf32-4738-9ee2-3f0027566cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_dataloaders(sampled_dataset, images_path, test_size=0.2, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b821f33-d629-4dd6-8e81-fa8c86df11f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/oren.matar/BlenderShaders/e/BLEN-11\n",
      "1/625\n",
      "2/625\n",
      "3/625\n",
      "4/625\n",
      "5/625\n",
      "6/625\n",
      "7/625\n",
      "8/625\n",
      "9/625\n",
      "10/625\n",
      "11/625\n",
      "12/625\n",
      "13/625\n",
      "14/625\n",
      "15/625\n",
      "16/625\n",
      "17/625\n",
      "18/625\n",
      "19/625\n",
      "20/625\n",
      "21/625\n",
      "22/625\n",
      "23/625\n",
      "24/625\n",
      "25/625\n",
      "26/625\n",
      "27/625\n",
      "28/625\n",
      "29/625\n",
      "30/625\n",
      "31/625\n",
      "32/625\n",
      "33/625\n",
      "34/625\n",
      "35/625\n",
      "36/625\n",
      "37/625\n",
      "38/625\n",
      "39/625\n",
      "40/625\n",
      "41/625\n",
      "42/625\n",
      "43/625\n",
      "44/625\n",
      "45/625\n",
      "46/625\n",
      "47/625\n",
      "48/625\n",
      "49/625\n",
      "50/625\n",
      "51/625\n",
      "52/625\n",
      "53/625\n",
      "54/625\n",
      "55/625\n",
      "56/625\n",
      "57/625\n",
      "58/625\n",
      "59/625\n",
      "60/625\n",
      "61/625\n",
      "62/625\n",
      "63/625\n",
      "64/625\n",
      "65/625\n",
      "66/625\n",
      "67/625\n",
      "68/625\n",
      "69/625\n",
      "70/625\n",
      "71/625\n",
      "72/625\n",
      "73/625\n",
      "74/625\n",
      "75/625\n",
      "76/625\n",
      "77/625\n",
      "78/625\n",
      "79/625\n",
      "80/625\n",
      "81/625\n",
      "82/625\n",
      "83/625\n",
      "84/625\n",
      "85/625\n",
      "86/625\n",
      "87/625\n",
      "88/625\n",
      "89/625\n",
      "90/625\n",
      "91/625\n",
      "92/625\n",
      "93/625\n",
      "94/625\n",
      "95/625\n",
      "96/625\n",
      "97/625\n",
      "98/625\n",
      "99/625\n",
      "100/625\n",
      "Starting eval using cuda\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"oren.matar/BlenderShaders\",\n",
    "    api_token=NEPTUNE_KEY,\n",
    ")\n",
    "run[\"parameters\"] = {\n",
    "    \"batch_size\": batch_size,\n",
    "    'model_type': 'VGG16',\n",
    "    'layers_taken': layers_to_take[0],\n",
    "    'criterion': 'CosineEmbeddingLoss',\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"optimizer\": \"Adam\",\n",
    "}\n",
    "t = time.time()\n",
    "\n",
    "criterion = torch.nn.CosineEmbeddingLoss(margin=0.3)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (img1, img2, labels, attributes) in enumerate(train_loader, start=1):\n",
    "        print(f'{batch_idx}/{len(train_loader)}')\n",
    "        img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "        embedding1 = model(img1)\n",
    "        embedding2 = model(img2)\n",
    "        \n",
    "        targets = 2 * labels - 1  # Convert 0/1 labels to -1/1\n",
    "        loss = criterion(embedding1, embedding2, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            \n",
    "            eval_auc = evaluate_model_by_attribute(model, test_loader)\n",
    "            run[\"train/loss\"].append(running_loss)\n",
    "            run['test/auc'] = eval_auc\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "    torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'loss': running_loss\n",
    "    }, f\"{models_path}+checkpoint_epoch_{epoch + 1}.pt\")\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5022e4c-e705-4a88-a1f8-2cfde04c5b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de3cbc9e-6222-4e8b-af5a-04e336c1d636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d871834a-549e-481d-b7b5-71dd3698f7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4220cd-88a4-4a91-a668-5aa5077c548d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5ec91-f077-41a4-920b-cda003ac5303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb162a-4401-48e1-b2d4-77c3e2069836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cab10c-c584-4d46-8cd4-83666ed96781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c272d6-ed0f-4bef-942f-97945e5577d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63024f43-9b04-4002-9be6-c9e7832f6ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
